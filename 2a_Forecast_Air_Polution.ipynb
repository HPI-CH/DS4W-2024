{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">dropping chunk=69: train=(0, 95), test=(28, 95)\n",
      "Train Rows: (23514, 42)\n",
      "Test Rows: (2070, 42)\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test sets\n",
    "from numpy import unique\n",
    "from numpy import nan\n",
    "from numpy import array\n",
    "from numpy import savetxt\n",
    "from pandas import read_csv\n",
    "\n",
    "# split the dataset by 'chunkID', return a dict of id to rows\n",
    "def to_chunks(values, chunk_ix=1):\n",
    "\tchunks = dict()\n",
    "\t# get the unique chunk ids\n",
    "\tchunk_ids = unique(values[:, chunk_ix])\n",
    "\t# group rows by chunk id\n",
    "\tfor chunk_id in chunk_ids:\n",
    "\t\tselection = values[:, chunk_ix] == chunk_id\n",
    "\t\tchunks[chunk_id] = values[selection, :]\n",
    "\treturn chunks\n",
    "\n",
    "# split each chunk into train/test sets\n",
    "def split_train_test(chunks, row_in_chunk_ix=2):\n",
    "\ttrain, test = list(), list()\n",
    "\t# first 5 days of hourly observations for train\n",
    "\tcut_point = 5 * 24\n",
    "\t# enumerate chunks\n",
    "\tfor k,rows in chunks.items():\n",
    "\t\t# split chunk rows by 'position_within_chunk'\n",
    "\t\ttrain_rows = rows[rows[:,row_in_chunk_ix] <= cut_point, :]\n",
    "\t\ttest_rows = rows[rows[:,row_in_chunk_ix] > cut_point, :]\n",
    "\t\tif len(train_rows) == 0 or len(test_rows) == 0:\n",
    "\t\t\tprint('>dropping chunk=%d: train=%s, test=%s' % (k, train_rows.shape, test_rows.shape))\n",
    "\t\t\tcontinue\n",
    "\t\t# store with chunk id, position in chunk, hour and all targets\n",
    "\t\tindices = [1,2,5] + [x for x in range(56,train_rows.shape[1])]\n",
    "\t\ttrain.append(train_rows[:, indices])\n",
    "\t\ttest.append(test_rows[:, indices])\n",
    "\treturn train, test\n",
    "\n",
    "# return a list of relative forecast lead times\n",
    "def get_lead_times():\n",
    "\treturn [1, 2 ,3, 4, 5, 10, 17, 24, 48, 72]\n",
    "\n",
    "# convert the rows in a test chunk to forecasts\n",
    "def to_forecasts(test_chunks, row_in_chunk_ix=1):\n",
    "\t# get lead times\n",
    "\tlead_times = get_lead_times()\n",
    "\t# first 5 days of hourly observations for train\n",
    "\tcut_point = 5 * 24\n",
    "\tforecasts = list()\n",
    "\t# enumerate each chunk\n",
    "\tfor rows in test_chunks:\n",
    "\t\tchunk_id = rows[0, 0]\n",
    "\t\t# enumerate each lead time\n",
    "\t\tfor tau in lead_times:\n",
    "\t\t\t# determine the row in chunk we want for the lead time\n",
    "\t\t\toffset = cut_point + tau\n",
    "\t\t\t# retrieve data for the lead time using row number in chunk\n",
    "\t\t\trow_for_tau = rows[rows[:,row_in_chunk_ix]==offset, :]\n",
    "\t\t\t# check if we have data\n",
    "\t\t\tif len(row_for_tau) == 0:\n",
    "\t\t\t\t# create a mock row [chunk, position, hour] + [nan...]\n",
    "\t\t\t\trow = [chunk_id, offset, nan] + [nan for _ in range(39)]\n",
    "\t\t\t\tforecasts.append(row)\n",
    "\t\t\telse:\n",
    "\t\t\t\t# store the forecast row\n",
    "\t\t\t\tforecasts.append(row_for_tau[0])\n",
    "\treturn array(forecasts)\n",
    "\n",
    "# load dataset\n",
    "dataset = read_csv('Datasets/dsg-hackathon/TrainingData.csv', header=0)\n",
    "# group data by chunks\n",
    "values = dataset.values\n",
    "chunks = to_chunks(values)\n",
    "# split into train/test\n",
    "train, test = split_train_test(chunks)\n",
    "# flatten training chunks to rows\n",
    "train_rows = array([row for rows in train for row in rows])\n",
    "# print(train_rows.shape)\n",
    "print('Train Rows: %s' % str(train_rows.shape))\n",
    "# reduce train to forecast lead times only\n",
    "test_rows = to_forecasts(test)\n",
    "print('Test Rows: %s' % str(test_rows.shape))\n",
    "# save datasets\n",
    "savetxt('Datasets/dsg-hackathon/naive_train.csv', train_rows, delimiter=',')\n",
    "savetxt('Datasets/dsg-hackathon/naive_test.csv', test_rows, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "note",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
